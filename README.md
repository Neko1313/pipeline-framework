# Pipeline Framework

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://github.com/company/pipeline-framework/workflows/Tests/badge.svg)](https://github.com/company/pipeline-framework/actions)
[![Coverage](https://codecov.io/gh/company/pipeline-framework/branch/main/graph/badge.svg)](https://codecov.io/gh/company/pipeline-framework)

–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π, –º–æ–¥—É–ª—å–Ω—ã–π framework –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–¥–µ–∂–Ω—ã—Ö data workflows —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Temporal –¥–ª—è distributed orchestration.

## üöÄ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **Plugin-Based –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** - –õ–µ–≥–∫–æ —Ä–∞—Å—à–∏—Ä—è–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- **Temporal Integration** - –ù–∞–¥–µ–∂–Ω–∞—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Temporal Workflow Service
- **YAML Configuration** - –î–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ pipeline —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π template
- **Auto-Discovery** - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ entry points
- **Type Safety** - –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ type hints –∏ Pydantic –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- **Observability** - Structured logging, Prometheus –º–µ—Ç—Ä–∏–∫–∏, distributed tracing
- **Developer Experience** - CLI –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, hot reload, –±–æ–≥–∞—Ç–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ß–µ—Ä–µ–∑ uv (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
uv add pipeline-framework

# –ß–µ—Ä–µ–∑ pip
pip install pipeline-framework
```

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏

```bash
# –° SQL –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
uv add "pipeline-framework[sql]"

# –° Temporal –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
uv add "pipeline-framework[temporal]"

# –ü–æ–ª–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
uv add "pipeline-framework[all]"
```

### –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/company/pipeline-framework.git
cd pipeline-framework

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
uv sync --group dev

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
uv run pytest

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–Ω—Ç–∏–Ω–≥–∞
uv run ruff check .
```

## üèÅ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ pipeline –ø—Ä–æ–µ–∫—Ç–∞
pipeline init my-data-pipeline

cd my-data-pipeline
```

### 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pipeline

–°–æ–∑–¥–∞–π—Ç–µ `pipeline.yaml`:

```yaml
pipeline:
  name: "customer-analytics"
  version: "1.0.0"
  description: "Customer data processing pipeline"
  
  variables:
    database_url: "${DATABASE_URL}"
    batch_size: 10000
  
  stages:
    - name: "extract-customers"
      component: "extractor/sql"
      config:
        connection_string: "${database_url}"
        query: "SELECT * FROM customers WHERE updated_at > :last_run"
        output_format: "pandas"
      timeout: "10m"
      
    - name: "transform-data"
      component: "transformer/pandas"
      depends_on: ["extract-customers"]
      config:
        script_content: |
          def transform(df):
              # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
              df['full_name'] = df['first_name'] + ' ' + df['last_name']
              return df.drop_duplicates()
      timeout: "15m"
      
    - name: "load-warehouse"
      component: "loader/sql"
      depends_on: ["transform-data"]
      config:
        connection_string: "${WAREHOUSE_URL}"
        target_table: "dim_customers"
        write_mode: "upsert"
        upsert_keys: ["customer_id"]
      timeout: "10m"
```

### 3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫

```bash
# –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
pipeline validate pipeline.yaml

# –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
pipeline run pipeline.yaml

# –ó–∞–ø—É—Å–∫ —Å –æ—Ç–ª–∞–¥–∫–æ–π
pipeline run pipeline.yaml --dry-run

# –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ Temporal
pipeline deploy pipeline.yaml --env production
```

## üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

Pipeline Framework –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Å —á–µ—Ç–∫–∏–º–∏ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è–º–∏:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Extractors    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Transformers   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Loaders      ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ SQL           ‚îÇ    ‚îÇ ‚Ä¢ Pandas        ‚îÇ    ‚îÇ ‚Ä¢ SQL           ‚îÇ
‚îÇ ‚Ä¢ API           ‚îÇ    ‚îÇ ‚Ä¢ Polars        ‚îÇ    ‚îÇ ‚Ä¢ File          ‚îÇ
‚îÇ ‚Ä¢ File          ‚îÇ    ‚îÇ ‚Ä¢ Custom        ‚îÇ    ‚îÇ ‚Ä¢ API           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Pipeline Core   ‚îÇ
                    ‚îÇ                 ‚îÇ
                    ‚îÇ ‚Ä¢ Registry      ‚îÇ
                    ‚îÇ ‚Ä¢ Config        ‚îÇ
                    ‚îÇ ‚Ä¢ Executor      ‚îÇ
                    ‚îÇ ‚Ä¢ Observability ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Temporal        ‚îÇ
                    ‚îÇ Integration     ‚îÇ
                    ‚îÇ                 ‚îÇ
                    ‚îÇ ‚Ä¢ Workflows     ‚îÇ
                    ‚îÇ ‚Ä¢ Activities    ‚îÇ
                    ‚îÇ ‚Ä¢ Scheduling    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

- **Extractors** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- **Transformers** - –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- **Loaders** - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ü–µ–ª–µ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã
- **Validators** - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
- **Stages** - –ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

#### Extractor

```python
from pipeline_core.components import BaseExtractor, ExecutionContext
from pydantic import BaseModel

class MyExtractorConfig(BaseModel):
    source_path: str
    format: str = "json"

class MyExtractor(BaseExtractor[dict, MyExtractorConfig]):
    @property
    def name(self) -> str:
        return "my-extractor"
    
    async def _execute_impl(self, context: ExecutionContext) -> dict:
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        with open(self.config.source_path) as f:
            return json.load(f)
```

#### Transformer

```python
from pipeline_core.components import BaseTransformer
import pandas as pd

class MyTransformer(BaseTransformer[pd.DataFrame, MyTransformerConfig]):
    @property
    def name(self) -> str:
        return "my-transformer"
    
    async def _execute_impl(self, context: ExecutionContext) -> pd.DataFrame:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
        input_data = context.get_previous_result("extract-stage").data
        
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        result = input_data.copy()
        result['processed_at'] = pd.Timestamp.now()
        
        return result
```

#### –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```python
# –ß–µ—Ä–µ–∑ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä
from pipeline_core.registry import register_component

@register_component("extractor", "my-custom")
class MyCustomExtractor(BaseExtractor):
    pass

# –ß–µ—Ä–µ–∑ entry points –≤ pyproject.toml
[project.entry-points."pipeline_framework.components"]
my-extractor = "my_package.extractors:MyExtractor"
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

#### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```yaml
pipeline:
  variables:
    # –ü—Ä–æ—Å—Ç–∞—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞
    database_url: "${DATABASE_URL}"
    
    # –° –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    batch_size: "${BATCH_SIZE:1000}"
    
    # Jinja2 template
    today: "{{ ds }}"
    formatted_date: "{{ now().strftime('%Y-%m-%d') }}"
```

#### Includes –∏ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ

```yaml
# base-config.yaml
defaults: &defaults
  timeout: "30m"
  retry_policy:
    maximum_attempts: 3

# pipeline.yaml  
include:
  - "base-config.yaml"

pipeline:
  stages:
    - name: "my-stage"
      <<: *defaults
      component: "extractor/sql"
```

#### Environment-specific –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

```yaml
pipeline:
  # ... –æ—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
  
environments:
  development:
    variables:
      batch_size: 100
    default_retry_policy:
      maximum_attempts: 1
      
  production:
    variables:
      batch_size: 10000
    monitoring:
      alert_on_failure: true
```

### Temporal Integration

#### –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ Temporal

```bash
# –ó–∞–ø—É—Å–∫ Temporal Server
temporal server start-dev

# –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ pipeline
pipeline deploy pipeline.yaml --temporal localhost:7233
```

#### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —á–µ—Ä–µ–∑ Temporal UI

–î–æ—Å—Ç—É–ø–Ω–æ –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:8233

### CLI Commands

```bash
# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
pipeline init <name>                    # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
pipeline validate <config>              # –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
pipeline run <config>                   # –ó–∞–ø—É—Å—Ç–∏—Ç—å pipeline –ª–æ–∫–∞–ª—å–Ω–æ
pipeline deploy <config>                # –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤ Temporal

# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏  
pipeline list                           # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
pipeline test --component <name>        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
pipeline dev <config>                   # Development —Å–µ—Ä–≤–µ—Ä

# –£—Ç–∏–ª–∏—Ç—ã
pipeline info                           # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ framework
```

## üîç Observability

### Structured Logging

```python
import structlog

logger = structlog.get_logger(__name__)

logger.info(
    "Processing customer data",
    customer_id=123,
    batch_size=1000,
    pipeline_id=context.pipeline_id
)
```

### Prometheus –ú–µ—Ç—Ä–∏–∫–∏

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏:

- `pipeline_component_executions_total` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- `pipeline_component_duration_seconds` - –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- `pipeline_data_processed_rows_total` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
- `pipeline_errors_total` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫

### Custom –ú–µ—Ç—Ä–∏–∫–∏

```python
from pipeline_core.observability import MetricsCollector

metrics = MetricsCollector()

# Counter
metrics.increment_counter("custom_events_total", {"event_type": "user_signup"})

# Histogram
metrics.observe_histogram("processing_duration", 0.5, {"component": "transformer"})

# Gauge
metrics.set_gauge("queue_size", 100, {"queue_name": "high_priority"})
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit —Ç–µ—Å—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```python
import pytest
from pipeline_core.components import ExecutionContext
from my_package.extractors import MyExtractor

@pytest.mark.asyncio
async def test_my_extractor():
    config = MyExtractorConfig(source_path="test_data.json")
    extractor = MyExtractor(config)
    
    context = ExecutionContext(
        pipeline_id="test",
        stage_name="test_extract"
    )
    
    result = await extractor.execute(context)
    
    assert result.success
    assert len(result.data) > 0
```

### Integration —Ç–µ—Å—Ç—ã

```python
@pytest.mark.asyncio
async def test_full_pipeline():
    from pipeline_core.config import load_pipeline_config
    from pipeline_core.pipeline import Pipeline
    
    config = load_pipeline_config("test_pipeline.yaml")
    pipeline = Pipeline(config)
    
    result = await pipeline.run()
    
    assert result.success
    assert len(result.stage_results) == 3
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å Docker

```yaml
# docker-compose.test.yml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: test
      POSTGRES_PASSWORD: test
  
  pipeline-test:
    build: .
    depends_on: [postgres]
    environment:
      DATABASE_URL: postgresql://postgres:test@postgres/test
    command: pytest tests/
```

## üõ†Ô∏è Development

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
uv sync --group dev

# Pre-commit hooks
pre-commit install

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ IDE (VSCode)
cp .vscode/settings.example.json .vscode/settings.json
```

### Code Quality

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:

- **Ruff** - –õ–∏–Ω—Ç–∏–Ω–≥ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
- **Pyright** - Type checking
- **Pytest** - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å asyncio –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
- **Pre-commit** - Git hooks –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –∫–æ–¥–∞
make lint
make test
make type-check

# –ò–ª–∏ —á–µ—Ä–µ–∑ uv
uv run ruff check .
uv run pytest
uv run pyright
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

1. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –ø–∞–∫–µ—Ç –≤ `packages/components/`
2. –ù–∞—Å–ª–µ–¥—É–π—Ç–µ –æ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
3. –î–æ–±–∞–≤—å—Ç–µ entry point –≤ `pyproject.toml`
4. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ—Å—Ç—ã
5. –û–±–Ω–æ–≤–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

### Release Process

```bash
# Bump –≤–µ—Ä—Å–∏–∏
uv run bump2version minor

# –°–æ–∑–¥–∞–Ω–∏–µ release
git tag v1.2.0
git push origin v1.2.0

# –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ PyPI
uv build
uv publish
```

## ü§ù Contributing

–ú—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ–º –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –ø—Ä–æ–µ–∫—Ç–∞! 

### –ö–∞–∫ –≤–Ω–µ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch: `git checkout -b feature/amazing-feature`
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã
4. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç: `make test`
5. Commit –∏–∑–º–µ–Ω–µ–Ω–∏—è: `git commit -m 'Add amazing feature'`
6. Push branch: `git push origin feature/amazing-feature`
7. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

### Coding Standards

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ type hints –¥–ª—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π
- –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ > 85%
- –°–ª–µ–¥—É–π—Ç–µ PEP 8 (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ Ruff)
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø—É–±–ª–∏—á–Ω—ã–µ API –≤ Google docstring —Ñ–æ—Ä–º–∞—Ç–µ
- –î–æ–±–∞–≤–ª—è–π—Ç–µ structured logging –¥–ª—è –≤–∞–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ MIT License - —Å–º. —Ñ–∞–π–ª [LICENSE](LICENSE) –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

## üôã‚Äç‚ôÇÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∫–∞

- üìß Email: [support@company.com](mailto:support@company.com)
- üí¨ Discussions: [GitHub Discussions](https://github.com/company/pipeline-framework/discussions)
- üêõ Issues: [GitHub Issues](https://github.com/company/pipeline-framework/issues)
- üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: [https://pipeline-framework.readthedocs.io](https://pipeline-framework.readthedocs.io)

## üó∫Ô∏è Roadmap

### v1.1 (Q2 2024)
- [ ] Polars transformer –ø–æ–¥–¥–µ—Ä–∂–∫–∞
- [ ] ClickHouse connector
- [ ] Web UI –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- [ ] Schema evolution –ø–æ–¥–¥–µ—Ä–∂–∫–∞

### v1.2 (Q3 2024)
- [ ] Apache Iceberg integration
- [ ] Real-time streaming –ø–æ–¥–¥–µ—Ä–∂–∫–∞
- [ ] dbt integration
- [ ] GraphQL API –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

### v2.0 (Q4 2024)
- [ ] Kubernetes operator
- [ ] Auto-scaling capabilities
- [ ] ML model deployment integration
- [ ] Multi-tenant support

---

## üèÜ Acknowledgments

–ü—Ä–æ–µ–∫—Ç –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω –ª—É—á—à–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏ –∏–∑:

- [Apache Airflow](https://airflow.apache.org/) - Workflow orchestration
- [Prefect](https://prefect.io/) - Modern data stack
- [dbt](https://getdbt.com/) - Analytics engineering
- [Temporal](https://temporal.io/) - Reliable workflows

**–°–æ–∑–¥–∞–Ω–æ —Å ‚ù§Ô∏è –∫–æ–º–∞–Ω–¥–æ–π Data Engineering**