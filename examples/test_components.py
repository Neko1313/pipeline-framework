#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ extractors –∏ transformers
"""

import tempfile
import pandas as pd
from pathlib import Path
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(
    0, os.path.join(os.path.dirname(__file__), "..", "packages", "pipeline-core", "src")
)
sys.path.insert(
    0, os.path.join(os.path.dirname(__file__), "..", "packages", "components", "extractors", "src")
)
sys.path.insert(
    0,
    os.path.join(os.path.dirname(__file__), "..", "packages", "components", "transformers", "src"),
)

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ pipeline-core
from pipeline_core import ExecutionContext, ExecutionStatus, PipelineYAMLParser, get_registry

# –ò–º–ø–æ—Ä—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
try:
    from pipeline_extractors import CSVExtractor
    from pipeline_transformers import DataTransformerComponent

    extractors_available = True
except ImportError as e:
    print(f"‚ö†Ô∏è  –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {e}")
    extractors_available = False


def create_sample_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ CSV —Ñ–∞–π–ª–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª
    temp_file = tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    data = {
        "id": range(1, 101),
        "name": [f"User_{i}" for i in range(1, 101)],
        "age": [20 + (i % 50) for i in range(100)],
        "salary": [30000 + (i * 1000) for i in range(100)],
        "department": ["IT", "HR", "Finance", "Marketing", "Sales"] * 20,
        "active": [True if i % 3 != 0 else False for i in range(100)],
    }

    df = pd.DataFrame(data)
    df.to_csv(temp_file.name, index=False)
    temp_file.close()

    print(f"üìÑ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π CSV —Ñ–∞–π–ª: {temp_file.name}")
    print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

    return temp_file.name


def test_csv_extractor():
    """–¢–µ—Å—Ç CSV —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CSV Extractor")
    print("=" * 50)

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    csv_file = create_sample_data()

    try:
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
        config = {
            "type": "csv-extractor",
            "file_path": csv_file,
            "delimiter": ",",
            "has_header": True,
            "output_format": "pandas",
        }

        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
        extractor = CSVExtractor(config)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
        context = ExecutionContext()
        result = extractor.execute(context)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        assert result.status == ExecutionStatus.SUCCESS
        assert result.data is not None
        assert result.processed_records > 0

        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {result.processed_records}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.execution_time:.3f} —Å–µ–∫")
        print(f"üìã –§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {result.data.shape}")
        print(f"üîç –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:")
        print(result.data.head(3))

        return result.data

    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(csv_file)


def test_data_transformer(input_data):
    """–¢–µ—Å—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Data Transformer")
    print("=" * 50)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
    config = {
        "type": "data-transformer",
        "source_stage": "extract",  # –°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞–¥–∏—é
        # –û–ø–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        "add_columns": {
            "salary_monthly": "salary / 12",
            "is_senior": "age >= 40",
            "full_info": "name + ' (' + department + ')'",
        },
        "filter_expression": "active == True and salary > 40000",
        "drop_columns": ["id"],
        "rename_columns": {"name": "employee_name", "department": "dept"},
        "sort_by": ["salary"],
        "sort_ascending": False,
        "sample_n": 20,
        "output_format": "pandas",
    }

    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
    transformer = DataTransformerComponent(config)

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏
    context = ExecutionContext()
    from pipeline_core import ExecutionResult, ExecutionStatus

    extract_result = ExecutionResult(
        status=ExecutionStatus.SUCCESS, data=input_data, processed_records=len(input_data)
    )
    context.set_stage_result("extract", extract_result)

    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é
    result = transformer.execute(context)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    assert result.status == ExecutionStatus.SUCCESS
    assert result.data is not None

    print(f"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {result.processed_records}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.execution_time:.3f} —Å–µ–∫")
    print(f"üìã –§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {result.data.shape}")
    print(f"üîç –ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {list(result.data.columns)}")
    print(f"üîç –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
    print(result.data.head())

    return result.data


def test_yaml_pipeline():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline —á–µ—Ä–µ–∑ YAML"""
    print("\nüìÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ YAML Pipeline")
    print("=" * 50)

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    csv_file = create_sample_data()

    try:
        # YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pipeline
        yaml_content = f"""
        metadata:
          name: "demo-pipeline"
          description: "–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π pipeline —Å extractors –∏ transformers"
          version: "1.0.0"

        variables:
          MIN_SALARY: 35000
          OUTPUT_FORMAT: "pandas"

        # –°—Ç–∞–¥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        extract:
          type: "csv-extractor"
          config:
            file_path: "{csv_file}"
            delimiter: ","
            has_header: true
            output_format: "${{OUTPUT_FORMAT}}"

        # –°—Ç–∞–¥–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö  
        transform:
          type: "data-transformer"
          depends_on: ["extract"]
          config:
            source_stage: "extract"
            add_columns:
              yearly_bonus: "salary * 0.1"
              experience_level: "case when age < 30 then 'Junior' when age < 45 then 'Middle' else 'Senior' end"
            filter_expression: "salary > ${{MIN_SALARY}} and active == True"
            sort_by: ["salary", "age"]
            sort_ascending: [false, true]
            drop_duplicates: true
            output_format: "${{OUTPUT_FORMAT}}"
        """

        # –ü–∞—Ä—Å–∏–º YAML
        parser = PipelineYAMLParser()
        pipeline_config = parser.parse_string(yaml_content)

        print(f"‚úÖ YAML —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω!")
        print(f"üìã Pipeline: {pipeline_config.metadata.name}")
        print(f"üìä –°—Ç–∞–¥–∏–π: {len(pipeline_config.stages)}")
        print(f"üîó –ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {pipeline_config.get_execution_order()}")

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–µ—Å—Ç—Ä –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        registry = get_registry()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        available_components = registry.list_components()
        print(f"üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {available_components}")

        # –ï—Å–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã, –≤—ã–ø–æ–ª–Ω—è–µ–º pipeline
        if "csv-extractor" in available_components and "data-transformer" in available_components:
            context = ExecutionContext()

            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–¥–∏–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
            for level in pipeline_config.get_execution_order():
                for stage_name in level:
                    stage_config = pipeline_config.stages[stage_name]

                    print(f"\n‚ñ∂Ô∏è  –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–∞–¥–∏–∏: {stage_name}")

                    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
                    component = registry.create_component(stage_config.type, stage_config.config)

                    # –í—ã–ø–æ–ª–Ω—è–µ–º
                    result = component.execute(context)
                    context.set_stage_result(stage_name, result)

                    print(f"   Status: {result.status}")
                    print(f"   Records: {result.processed_records}")
                    print(f"   Time: {result.execution_time:.3f}s")

            print(f"\nüéâ Pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É
            summary = context.get_execution_summary()
            print(f"üìä –°–≤–æ–¥–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:")
            print(f"   –í—Å–µ–≥–æ —Å—Ç–∞–¥–∏–π: {summary['total_stages']}")
            print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {summary['successful_stages']}")
            print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {summary['failed_stages']}")
            print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {summary['total_execution_time']:.3f}s")

        else:
            print("‚ö†Ô∏è  –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ —Ä–µ–µ—Å—Ç—Ä–µ")

    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(csv_file)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Pipeline Components")
    print("=" * 60)

    if not extractors_available:
        print("‚ùå –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –ø–∞–∫–µ—Ç–æ–≤.")
        return

    try:
        # –¢–µ—Å—Ç 1: CSV Extractor
        data = test_csv_extractor()

        # –¢–µ—Å—Ç 2: Data Transformer
        transformed_data = test_data_transformer(data)

        # –¢–µ—Å—Ç 3: YAML Pipeline
        test_yaml_pipeline()

        print(f"\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üí° –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production!")

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ç–µ—Å—Ç–æ–≤: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
