# CSV Extractor - –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

–ú–æ—â–Ω—ã–π –∏ –≥–∏–±–∫–∏–π CSV —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–ª—è Pipeline Framework —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### ‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
- **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—ã–≤–æ–¥–∞**: pandas DataFrame, Polars DataFrame, dict, list
- **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ**: –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
- **Chunked –æ–±—Ä–∞–±–æ—Ç–∫–∞**: —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–æ–ª—å—à–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
- **–ì–∏–±–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**: 20+ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: pandas query —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
- **–í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫**: —á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
- **–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
- **–¢–∏–ø–∏–∑–∞—Ü–∏—è**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏ —Ä—É—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö

### ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–∞—á–µ—Å—Ç–≤–æ
- **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã**: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∏—Ö —Ç–∏–ø—ã
- **–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö**: –º–∏–Ω–∏–º—É–º/–º–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Å–µ–π
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**: —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –¥–∞–Ω–Ω—ã–º
- **Health check**: –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤

### ‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ**: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–≤–∏–∂–∫–æ–≤
- **–ü–∞–º—è—Ç—å**: –∫–æ–Ω—Ç—Ä–æ–ª—å –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ chunking
- **–ö–æ–¥–∏—Ä–æ–≤–∫–∏**: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–æ–∫
- **–§–æ—Ä–º–∞—Ç—ã**: CSV, TSV –∏ –¥—Ä—É–≥–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ë–∞–∑–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install pandas>=2.0.0

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
pip install polars>=0.20.0          # –î–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
pip install aiofiles>=23.0.0        # –î–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è
pip install aiocsv>=1.3.0           # –î–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è CSV
```

## üîß –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä

```python
from pipeline_core import ExecutionContext
from pipeline_extractors.file.csv_extractor import CSVExtractor

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
config = {
    "type": "csv-extractor",
    "file_path": "data.csv"
}

extractor = CSVExtractor(config)
context = ExecutionContext()
result = extractor.execute(context)

if result.status.value == "success":
    df = result.data  # pandas DataFrame
    print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {result.processed_records} –∑–∞–ø–∏—Å–µ–π")
```

### YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```yaml
extract_users:
  type: "csv-extractor"
  config:
    file_path: "users.csv"
    delimiter: ","
    encoding: "utf-8"
    output_format: "pandas"
    required_columns: ["id", "name", "email"]
```

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∞–π–ª–∞

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `file_path` | str/Path | **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π** | –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É |
| `delimiter` | str | `","` | –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∫–æ–ª–æ–Ω–æ–∫ |
| `encoding` | str | `"utf-8"` | –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ |
| `has_header` | bool | `true` | –ï—Å—Ç—å –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ |
| `skip_rows` | int | `0` | –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å N —Å—Ç—Ä–æ–∫ —Å–≤–µ—Ä—Ö—É |
| `max_rows` | int | `null` | –ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–æ–∫ –¥–ª—è —á—Ç–µ–Ω–∏—è |

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `null_values` | list[str] | `["", "NULL", "null", ...]` | –ó–Ω–∞—á–µ–Ω–∏—è = NULL |
| `infer_schema` | bool | `true` | –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ |
| `column_types` | dict | `null` | –Ø–≤–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–ª–æ–Ω–æ–∫ |
| `output_format` | str | `"pandas"` | pandas/polars/dict/list |

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤—ã–±–æ—Ä–∫–∞

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `select_columns` | list[str] | `null` | –í—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ |
| `rename_columns` | dict | `null` | –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ |
| `filter_condition` | str | `null` | –£—Å–ª–æ–≤–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ |

### –í–∞–ª–∏–¥–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `required_columns` | list[str] | `[]` | –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ |
| `min_records` | int | `null` | –ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π |
| `max_records` | int | `null` | –ú–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Å–µ–π |

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `chunk_size` | int | `null` | –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ |
| `use_async` | bool | `false` | –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ |
| `memory_limit` | str | `null` | –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏ |

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `skip_bad_lines` | bool | `false` | –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ |
| `error_tolerance` | float | `0.0` | –î–æ–ø—É—Å—Ç–∏–º–∞—è –¥–æ–ª—è –æ—à–∏–±–æ–∫ (0.0-1.0) |

## üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### 1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫

```python
config = {
    "type": "csv-extractor",
    "file_path": "employees.csv",
    "select_columns": ["name", "email", "salary", "department"],
    "rename_columns": {"name": "full_name", "email": "email_address"},
    "filter_condition": "salary > 50000 and department in ['IT', 'Engineering']",
    "output_format": "pandas"
}
```

### 2. –¢–∏–ø–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

```python
config = {
    "type": "csv-extractor", 
    "file_path": "data.csv",
    "column_types": {
        "id": "int",
        "name": "string", 
        "price": "float",
        "active": "bool",
        "created_at": "datetime"
    },
    "infer_schema": false
}
```

### 3. Chunked –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤

```python
config = {
    "type": "csv-extractor",
    "file_path": "big_data.csv",
    "chunk_size": 1000,           # –ß–∏—Ç–∞—Ç—å –ø–æ 1000 —Å—Ç—Ä–æ–∫
    "filter_condition": "active == True",
    "max_rows": 50000,            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    "output_format": "pandas"
}
```

### 4. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ

```python
config = {
    "type": "csv-extractor",
    "file_path": "large_file.csv",
    "use_async": True,
    "output_format": "dict",      # –õ—É—á—à–µ –¥–ª—è async
    "skip_bad_lines": True,
    "error_tolerance": 0.05       # –î–æ–ø—É—Å–∫–∞—Ç—å 5% –æ—à–∏–±–æ–∫
}
```

### 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```python
config = {
    "type": "csv-extractor",
    "file_path": "messy_data.csv",
    "skip_bad_lines": True,       # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    "error_tolerance": 0.1,       # –î–æ–ø—É—Å–∫–∞—Ç—å 10% –æ—à–∏–±–æ–∫
    "null_values": ["", "NULL", "N/A", "unknown", "missing"],
    "infer_schema": False,        # –ß–∏—Ç–∞—Ç—å –≤—Å–µ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏ —Å–Ω–∞—á–∞–ª–∞
    "output_format": "pandas"
}
```

### 6. –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

```python
config = {
    "type": "csv-extractor",
    "file_path": "users.csv",
    "required_columns": ["user_id", "email", "name"],
    "min_records": 100,           # –ú–∏–Ω–∏–º—É–º 100 –∑–∞–ø–∏—Å–µ–π
    "max_records": 1000000,       # –ú–∞–∫—Å–∏–º—É–º 1M –∑–∞–ø–∏—Å–µ–π
    "filter_condition": "email.str.contains('@')",  # –í–∞–ª–∏–¥–Ω—ã–µ email
    "output_format": "pandas"
}
```

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Pipeline

### YAML Pipeline

```yaml
metadata:
  name: "data-processing-pipeline"
  version: "1.0.0"

variables:
  DATA_DIR: "./data"
  MIN_SALARY: 30000

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
extract_raw:
  type: "csv-extractor"
  config:
    file_path: "${DATA_DIR}/employees.csv"
    output_format: "pandas"
    required_columns: ["id", "name", "salary"]

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–æ–ø–ª–∞—á–∏–≤–∞–µ–º—ã—Ö
extract_high_earners:
  type: "csv-extractor"
  config:
    file_path: "${DATA_DIR}/employees.csv"
    filter_condition: "salary >= ${MIN_SALARY}"
    column_types:
      salary: "float"
      id: "int"
    output_format: "dict"

# –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª —Å chunking
extract_transactions:
  type: "csv-extractor"
  config:
    file_path: "${DATA_DIR}/transactions.csv"
    chunk_size: 5000
    select_columns: ["date", "amount", "user_id"]
    filter_condition: "amount > 0"
    max_rows: 100000
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from pipeline_core import PipelineYAMLParser, ExecutionContext, get_registry

# –ü–∞—Ä—Å–∏–º pipeline
parser = PipelineYAMLParser()
config = parser.parse_file("pipeline.yml")

# –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–¥–∏–∏
registry = get_registry()
context = ExecutionContext()

for level in config.get_execution_order():
    for stage_name in level:
        stage_config = config.stages[stage_name]
        
        component = registry.create_component(
            stage_config.type,
            stage_config.config
        )
        
        result = component.execute(context)
        context.set_stage_result(stage_name, result)
        
        print(f"‚úÖ {stage_name}: {result.processed_records} –∑–∞–ø–∏—Å–µ–π")
```

## üö® –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

### –¢–∏–ø—ã –æ—à–∏–±–æ–∫

1. **PipelineConfigError**: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
2. **PipelineDataError**: –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏
3. **PipelineExecutionError**: –û—à–∏–±–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏

```python
# –°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º - –ø–∞–¥–∞—Ç—å –ø—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ
config_strict = {
    "skip_bad_lines": False,
    "error_tolerance": 0.0
}

# –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º - –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
config_tolerant = {
    "skip_bad_lines": True,
    "error_tolerance": 0.1,  # –î–æ 10% –æ—à–∏–±–æ–∫
    "infer_schema": False    # –ë–µ–∑–æ–ø–∞—Å–Ω–µ–µ
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
result = extractor.execute(context)
if result.status.value == "failed":
    print(f"–û—à–∏–±–∫–∞: {result.error_message}")
    # –õ–æ–≥–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
```

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

**–î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (< 100MB)**:
```python
config = {
    "file_path": "small.csv",
    "output_format": "pandas",
    "infer_schema": True
}
```

**–î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ (100MB - 1GB)**:
```python
config = {
    "file_path": "medium.csv",
    "chunk_size": 10000,
    "output_format": "pandas"
}
```

**–î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (> 1GB)**:
```python
config = {
    "file_path": "large.csv",
    "output_format": "polars",    # –ë—ã—Å—Ç—Ä–µ–µ pandas
    "chunk_size": 50000,          # –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å polars –±–µ–∑ chunking
    "use_async": False            # Polars –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç async
}
```

**–î–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤**:
```python
config = {
    "file_path": "huge.csv",
    "use_async": True,
    "chunk_size": 1000,           # –ú–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏
    "output_format": "dict",      # –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏
    "max_rows": 1000000          # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –æ–±—ä–µ–º
}
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

| –ú–µ—Ç–æ–¥ | –°–∫–æ—Ä–æ—Å—Ç—å | –ü–∞–º—è—Ç—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|-------|----------|--------|--------------------|
| pandas –æ–±—ã—á–Ω—ã–π | ‚≠ê‚≠ê‚≠ê | ‚≠ê | –§–∞–π–ª—ã < 500MB |
| pandas chunked | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | –§–∞–π–ª—ã > 500MB |
| polars | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | –õ—é–±—ã–µ —Ä–∞–∑–º–µ—Ä—ã |
| async | ‚≠ê‚≠ê | ‚≠ê‚≠ê | I/O bound –∑–∞–¥–∞—á–∏ |

## üîß –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤

```python
from pipeline_extractors.file.csv_extractor import CSVExtractor, CSVExtractorConfig

@register_component("excel-like-csv")
class ExcelLikeCSVExtractor(CSVExtractor):
    """CSV —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ Excel"""
    
    def get_config_model(self):
        class ExcelCSVConfig(CSVExtractorConfig):
            delimiter: str = Field(default=";", frozen=True)
            encoding: str = Field(default="cp1251", frozen=True)
            decimal: str = Field(default=",")  # –ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
        
        return ExcelCSVConfig
```

### –ö–∞—Å—Ç–æ–º–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
class DataCleaningExtractor(CSVExtractor):
    def _post_process_data(self, data):
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if isinstance(data, pd.DataFrame):
            # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
            for col in data.select_dtypes(include=['object']).columns:
                data[col] = data[col].str.strip()
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º email
            if 'email' in data.columns:
                data['email'] = data['email'].str.lower()
        
        return super()._post_process_data(data)
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
cd packages/components/extractors
uv run pytest tests/test_csv_extractor.py -v

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
uv run pytest tests/test_csv_extractor.py::TestCSVExtractorBasic::test_basic_extraction_pandas -v

# –¢–µ—Å—Ç—ã —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
uv run pytest tests/test_csv_extractor.py --cov=src/pipeline_extractors --cov-report=html
```

## üéØ –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

### ‚úÖ –î–µ–ª–∞–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ

1. **–í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ required_columns** –¥–ª—è –≤–∞–∂–Ω—ã—Ö –ø–æ–ª–µ–π
2. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é** –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
3. **–ó–∞–¥–∞–≤–∞–π—Ç–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö** —è–≤–Ω–æ –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ chunking** –¥–ª—è —Ñ–∞–π–ª–æ–≤ > 100MB
5. **–í–∫–ª—é—á–∞–π—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é** min_records/max_records

### ‚ùå –ò–∑–±–µ–≥–∞–π—Ç–µ –æ—à–∏–±–æ–∫

1. **–ù–µ —á–∏—Ç–∞–π—Ç–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏** –µ—Å–ª–∏ –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ
2. **–ù–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–π—Ç–µ –æ—à–∏–±–∫–∏** –±–µ–∑ error_tolerance
3. **–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ async —Å polars** - –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ
4. **–ù–µ –ø–æ–ª–∞–≥–∞–π—Ç–µ—Å—å –Ω–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤** –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
5. **–ù–µ –∑–∞–±—ã–≤–∞–π—Ç–µ –ø—Ä–æ –∫–æ–¥–∏—Ä–æ–≤–∫–∏** –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –Ω–µ-ASCII —Ç–µ–∫—Å—Ç–æ–º

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞ –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –º–∞–ª–æ–º –æ–±—Ä–∞–∑—Ü–µ –¥–∞–Ω–Ω—ã—Ö
4. –í–∫–ª—é—á–∏—Ç–µ skip_bad_lines –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
5. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –ø—Ä–∏–º–µ—Ä–∞–º –≤ `examples/`

---

**–í–µ—Ä—Å–∏—è**: 0.1.0  
**–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: Python 3.11+  
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: pandas>=2.0.0  
**–õ–∏—Ü–µ–Ω–∑–∏—è**: Apache 2.0