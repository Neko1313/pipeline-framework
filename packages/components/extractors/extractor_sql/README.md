# SQL Extractor

[![Python Version](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tests](https://github.com/company/pipeline-framework/workflows/Tests/badge.svg)](https://github.com/company/pipeline-framework/actions)
[![Coverage](https://codecov.io/gh/company/pipeline-framework/branch/main/graph/badge.svg)](https://codecov.io/gh/company/pipeline-framework)

–ú–æ—â–Ω—ã–π –∏ –≥–∏–±–∫–∏–π SQL Extractor –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–º–∫–∞—Ö pipeline framework. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, connection pooling, retry –º–µ—Ö–∞–Ω–∏–∑–º—ã –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å Temporal –¥–ª—è orchestration.

## üöÄ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ë–î**: PostgreSQL, MySQL, SQLite, Oracle, SQL Server, Snowflake, BigQuery
- **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ**: –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è asyncio –∏ SQLAlchemy async
- **Connection Pooling**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
- **Retry –º–µ—Ö–∞–Ω–∏–∑–º—ã**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –ø—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–±–æ—è—Ö
- **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö**: pandas, polars, dict, raw –¥–∞–Ω–Ω—ã–µ
- **Streaming –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö dataset'–æ–≤ –ø–æ —á–∞—Å—Ç—è–º
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Prometheus –∏ structured logging
- **Type Safety**: –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ type hints –∏ Pydantic –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- **CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å**: –£–¥–æ–±–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–∫–∏

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ß–µ—Ä–µ–∑ uv (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
uv add extractor-sql

# –ß–µ—Ä–µ–∑ pip
pip install extractor-sql
```

### –° –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥—Ä–∞–π–≤–µ—Ä–∞–º–∏ –ë–î

```bash
# PostgreSQL
uv add "extractor-sql[postgresql]"

# MySQL
uv add "extractor-sql[mysql]"

# Oracle
uv add "extractor-sql[oracle]"

# SQL Server
uv add "extractor-sql[mssql]"

# Snowflake
uv add "extractor-sql[snowflake]"

# BigQuery
uv add "extractor-sql[bigquery]"

# –í—Å–µ –¥—Ä–∞–π–≤–µ—Ä—ã
uv add "extractor-sql[all]"
```

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/company/pipeline-framework.git
cd pipeline-framework

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
uv sync --group dev
```

## üèÅ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä

```python
import asyncio
from extractor_sql import SQLExtractor, SQLExtractorConfig, QueryConfig

async def main():
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = SQLExtractorConfig(
        connection_string="postgresql+asyncpg://user:password@localhost:5432/mydb",
        query_config=QueryConfig(
            query="SELECT * FROM users WHERE created_at > :start_date",
            parameters={"start_date": "2024-01-01"}
        ),
        output_format="pandas"
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è extractor'–∞
    extractor = SQLExtractor(config)
    await extractor.initialize()
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    from pipeline_core.components.base import ExecutionContext
    context = ExecutionContext(pipeline_id="demo", stage_name="extract_users")
    
    result = await extractor.execute(context)
    
    if result.success:
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(result.data)} —Å—Ç—Ä–æ–∫")
        print(result.data.head())
    else:
        print(f"–û—à–∏–±–∫–∞: {result.error}")
    
    # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
    await extractor.cleanup()

# –ó–∞–ø—É—Å–∫
asyncio.run(main())
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ–∞–±—Ä–∏—á–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏

```python
from extractor_sql import create_extractor

# –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ extractor'–∞
extractor = create_extractor(
    connection_string="sqlite+aiosqlite:///data.db",
    query="SELECT name, age FROM users",
    output_format="polars",
    fetch_size=5000
)
```

## üõ†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

```python
from extractor_sql import (
    SQLExtractorConfig,
    QueryConfig,
    ConnectionPoolConfig,
    RetryConfig
)

config = SQLExtractorConfig(
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    connection_string="postgresql+asyncpg://user:pass@localhost:5432/db",
    dialect="postgresql",  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    query_config=QueryConfig(
        query="SELECT * FROM users WHERE department = :dept",
        parameters={"dept": "Engineering"},
        timeout=300.0,  # 5 –º–∏–Ω—É—Ç
        fetch_size=10000,
        stream_results=False
    ),
    
    # –§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    output_format="pandas",  # pandas, polars, dict, raw
    chunk_size=None,  # –î–ª—è streaming
    
    # Connection pooling
    pool_config=ConnectionPoolConfig(
        pool_size=5,
        max_overflow=10,
        pool_timeout=30.0,
        pool_recycle=3600,  # 1 —á–∞—Å
        pool_pre_ping=True
    ),
    
    # Retry –ø–æ–ª–∏—Ç–∏–∫–∞
    retry_config=RetryConfig(
        max_attempts=3,
        initial_wait=1.0,
        max_wait=60.0,
        multiplier=2.0,
        jitter=True
    ),
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ SQLAlchemy
    engine_options={"echo": False},
    
    # SSL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    ssl_config={"sslmode": "require"}
)
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ YAML

```yaml
# config.yaml
connection_string: "postgresql+asyncpg://user:password@localhost:5432/mydb"
dialect: "postgresql"

query_config:
  query: |
    SELECT 
      u.name,
      u.email,
      d.name as department_name,
      COUNT(o.id) as order_count
    FROM users u
    JOIN departments d ON u.department_id = d.id
    LEFT JOIN orders o ON u.id = o.user_id
    WHERE u.is_active = :is_active
    GROUP BY u.id, u.name, u.email, d.name
    ORDER BY order_count DESC
  parameters:
    is_active: true
  timeout: 600.0
  fetch_size: 5000
  stream_results: false

output_format: "pandas"

pool_config:
  pool_size: 10
  max_overflow: 20
  pool_timeout: 30.0
  pool_recycle: 3600
  pool_pre_ping: true

retry_config:
  max_attempts: 3
  initial_wait: 1.0
  max_wait: 60.0
  multiplier: 2.0
  jitter: true

engine_options:
  echo: false
  isolation_level: "READ_COMMITTED"
```

```python
# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ YAML
import yaml
from extractor_sql import SQLExtractorConfig

with open("config.yaml") as f:
    config_data = yaml.safe_load(f)

config = SQLExtractorConfig(**config_data)
extractor = SQLExtractor(config)
```

## üóÉÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

### PostgreSQL

```python
from extractor_sql import PostgresSQLExtractor, SQLExtractorConfig

config = SQLExtractorConfig(
    connection_string="postgresql+asyncpg://user:pass@localhost:5432/db",
    query_config=QueryConfig(query="SELECT * FROM users")
)

extractor = PostgresSQLExtractor(config)
```

**Connection strings –ø—Ä–∏–º–µ—Ä—ã:**
- `postgresql://user:password@localhost:5432/database`
- `postgresql+asyncpg://user:password@localhost:5432/database`
- `postgresql+asyncpg://user:password@localhost:5432/database?sslmode=require`

### MySQL

```python
from extractor_sql import MySQLExtractor, SQLExtractorConfig

config = SQLExtractorConfig(
    connection_string="mysql+aiomysql://user:pass@localhost:3306/db",
    query_config=QueryConfig(query="SELECT * FROM users")
)

extractor = MySQLExtractor(config)
```

**Connection strings –ø—Ä–∏–º–µ—Ä—ã:**
- `mysql://user:password@localhost:3306/database`
- `mysql+aiomysql://user:password@localhost:3306/database`
- `mysql+asyncmy://user:password@localhost:3306/database`

### SQLite

```python
from extractor_sql import SQLiteExtractor, SQLExtractorConfig

config = SQLExtractorConfig(
    connection_string="sqlite+aiosqlite:///path/to/database.db",
    query_config=QueryConfig(query="SELECT * FROM users")
)

extractor = SQLiteExtractor(config)
```

**Connection strings –ø—Ä–∏–º–µ—Ä—ã:**
- `sqlite+aiosqlite:///absolute/path/to/database.db`
- `sqlite+aiosqlite:///./relative/path/to/database.db`
- `sqlite+aiosqlite:///:memory:` (in-memory database)

### Snowflake

```python
config = SQLExtractorConfig(
    connection_string="snowflake://user:pass@account.region/database/schema?warehouse=wh&role=role",
    query_config=QueryConfig(query="SELECT * FROM users")
)
```

### BigQuery

```python
config = SQLExtractorConfig(
    connection_string="bigquery://project/dataset",
    query_config=QueryConfig(query="SELECT * FROM `project.dataset.table`"),
    engine_options={
        "credentials_path": "/path/to/service-account.json"
    }
)
```

## üìä –§–æ—Ä–º–∞—Ç—ã –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### pandas DataFrame (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)

```python
config = SQLExtractorConfig(
    connection_string="...",
    query_config=QueryConfig(query="SELECT * FROM users"),
    output_format="pandas"
)

result = await extractor.execute(context)
df = result.data  # pandas.DataFrame
print(df.dtypes)
print(df.describe())
```

### polars DataFrame

```python
config = SQLExtractorConfig(
    # ...
    output_format="polars"
)

result = await extractor.execute(context)
df = result.data  # polars.DataFrame
print(df.schema)
print(df.describe())
```

### –°–ª–æ–≤–∞—Ä–∏ (Records)

```python
config = SQLExtractorConfig(
    # ...
    output_format="dict"
)

result = await extractor.execute(context)
records = result.data  # List[Dict[str, Any]]
for record in records:
    print(record)
```

### Raw –¥–∞–Ω–Ω—ã–µ

```python
config = SQLExtractorConfig(
    # ...
    output_format="raw"
)

result = await extractor.execute(context)
rows = result.data  # List[Tuple]
for row in rows:
    print(row)
```

## üîÑ Streaming –±–æ–ª—å—à–∏—Ö dataset'–æ–≤

–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ streaming:

```python
config = SQLExtractorConfig(
    connection_string="postgresql+asyncpg://user:pass@localhost:5432/db",
    query_config=QueryConfig(
        query="SELECT * FROM large_table",
        fetch_size=10000,  # –†–∞–∑–º–µ—Ä batch'–∞
        stream_results=True
    ),
    chunk_size=5000,  # –†–∞–∑–º–µ—Ä chunk'–∞ –¥–ª—è processing
    output_format="pandas"
)

extractor = SQLExtractor(config)
await extractor.initialize()

result = await extractor.execute(context)

# –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –Ω–æ –æ–Ω–∏ –∏–∑–≤–ª–µ–∫–∞–ª–∏—Å—å –ø–æ —á–∞—Å—Ç—è–º
print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(result.data)} —Å—Ç—Ä–æ–∫")
```

## üîß CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

SQL Extractor –≤–∫–ª—é—á–∞–µ—Ç –º–æ—â–Ω—ã–π CLI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–∫–∏:

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

```bash
extractor-sql test-connection "postgresql://user:pass@localhost:5432/db"
```

### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

```bash
extractor-sql extract \
  "postgresql://user:pass@localhost:5432/db" \
  "SELECT * FROM users WHERE age > 25" \
  --output-format pandas \
  --output results.csv \
  --timeout 300 \
  --verbose
```

### –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞

```bash
extractor-sql analyze-query "SELECT u.*, COUNT(o.id) FROM users u LEFT JOIN orders o ON u.id = o.user_id GROUP BY u.id"
```

### –ó–∞–ø—É—Å–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

```bash
extractor-sql run-from-config config.yaml --show-data --max-rows 20
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```bash
extractor-sql generate-config config.yaml \
  --connection-string "postgresql://user:pass@localhost/db" \
  --query "SELECT * FROM users" \
  --format yaml
```

### –ü–æ–∫–∞–∑–∞—Ç—å –≤–µ—Ä—Å–∏—é

```bash
extractor-sql version
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

SQL Extractor –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ Prometheus:

### –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- `sql_extractor_queries_total` - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- `sql_extractor_query_duration_seconds` - –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
- `sql_extractor_rows_extracted_total` - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
- `sql_extractor_active_connections` - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π

### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import structlog

# –õ–æ–≥–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
logger = structlog.get_logger(__name__)

# –ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:
# 2024-01-20T10:30:45.123Z [info] SQL data extraction completed 
#   name=postgresql-extractor rows=15420 duration=45.67 pipeline_id=user_analytics
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Grafana

–°–æ–∑–¥–∞–π—Ç–µ –¥–∞—à–±–æ—Ä–¥ –≤ Grafana –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:

```promql
# –ó–∞–ø—Ä–æ—Å—ã –≤ —Å–µ–∫—É–Ω–¥—É
rate(sql_extractor_queries_total[5m])

# –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤
rate(sql_extractor_query_duration_seconds_sum[5m]) / 
rate(sql_extractor_query_duration_seconds_count[5m])

# –°—Ç—Ä–æ–∫–∏ –≤ —Å–µ–∫—É–Ω–¥—É
rate(sql_extractor_rows_extracted_total[5m])

# –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
sql_extractor_active_connections
```

## üîç –û—Ç–ª–∞–¥–∫–∞ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π

### –í–∫–ª—é—á–µ–Ω–∏–µ debug –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```python
import logging
import structlog

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.DEBUG)
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

# –í–∫–ª—é—á–µ–Ω–∏–µ debug –¥–ª—è SQLAlchemy
config = SQLExtractorConfig(
    # ...
    engine_options={"echo": True}  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ SQL –∑–∞–ø—Ä–æ—Å—ã
)
```

### –û–±—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

#### 1. –û—à–∏–±–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

```python
# –ü—Ä–æ–≤–µ—Ä–∫–∞ connection string
from extractor_sql.utils import validate_connection_string

is_valid, error = validate_connection_string("your-connection-string")
if not is_valid:
    print(f"–û—à–∏–±–∫–∞: {error}")
```

#### 2. –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã

```python
# –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞
from extractor_sql.utils import estimate_query_cost

cost = estimate_query_cost("your-sql-query")
print(f"–°–ª–æ–∂–Ω–æ—Å—Ç—å: {cost['complexity']}")
print(f"JOIN'–æ–≤: {cost['join_count']}")
print(f"–ü–æ–¥–∑–∞–ø—Ä–æ—Å–æ–≤: {cost['subquery_count']}")
```

#### 3. –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é

```python
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è DataFrame
from extractor_sql.utils import optimize_dataframe_memory

optimized_df = optimize_dataframe_memory(result.data)
print(f"–≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: {original_size - optimized_size} bytes")
```

#### 4. Timeout'—ã

```python
# –£–≤–µ–ª–∏—á–µ–Ω–∏–µ timeout'–æ–≤
config = SQLExtractorConfig(
    # ...
    query_config=QueryConfig(
        query="...",
        timeout=1800.0  # 30 –º–∏–Ω—É—Ç
    ),
    pool_config=ConnectionPoolConfig(
        pool_timeout=60.0  # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    )
)
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã
pytest

# –¢–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã
pytest -m "unit"

# –¢–æ–ª—å–∫–æ integration —Ç–µ—Å—Ç—ã (—Ç—Ä–µ–±—É—é—Ç Docker)
pytest -m "integration"

# –ò—Å–∫–ª—é—á–∏—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
pytest -m "not slow"

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º –∫–æ–¥–∞
pytest --cov=extractor_sql --cov-report=html

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
pytest -n auto
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ë–î

```bash
# PostgreSQL (—á–µ—Ä–µ–∑ testcontainers)
pytest -m "postgresql" 

# MySQL (—á–µ—Ä–µ–∑ testcontainers)
pytest -m "mysql"

# SQLite (–ª–æ–∫–∞–ª—å–Ω–æ)
pytest -m "sqlite"
```

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤

```python
import pytest
from extractor_sql import SQLExtractor, SQLExtractorConfig, QueryConfig

@pytest.mark.asyncio
async def test_my_extraction():
    config = SQLExtractorConfig(
        connection_string="sqlite+aiosqlite:///:memory:",
        query_config=QueryConfig(query="SELECT 1 as test_column")
    )
    
    extractor = SQLExtractor(config)
    await extractor.initialize()
    
    from pipeline_core.components.base import ExecutionContext
    context = ExecutionContext(pipeline_id="test", stage_name="test")
    
    result = await extractor.execute(context)
    
    assert result.success is True
    assert len(result.data) == 1
    assert result.data.iloc[0]["test_column"] == 1
    
    await extractor.cleanup()
```

## üîß –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏ –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è

### –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ extractor'–∞

```python
from extractor_sql import SQLExtractor, SQLExtractorConfig
from typing import Optional

class CustomSQLExtractor(SQLExtractor):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π SQL Extractor —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    
    def __init__(self, config: SQLExtractorConfig, **kwargs):
        super().__init__(config, name="custom-sql-extractor", **kwargs)
    
    async def _preprocess_query(self, query: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º"""
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –ª–æ–≥–∏–∫—É
        if "users" in query.lower():
            query += " AND is_deleted = false"
        return query
    
    async def _postprocess_data(self, data):
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        if hasattr(data, "columns"):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –≤ snake_case
            data.columns = [col.lower().replace(" ", "_") for col in data.columns]
        return data
    
    async def execute(self, context):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º execute –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –ª–æ–≥–∏–∫–∏"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        original_query = self.config.query_config.query
        self.config.query_config.query = await self._preprocess_query(original_query)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –ª–æ–≥–∏–∫—É
        result = await super().execute(context)
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        if result.success and result.data is not None:
            result.data = await self._postprocess_data(result.data)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        self.config.query_config.query = original_query
        
        return result
```

### –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö

```python
from extractor_sql.components import SQLExtractor
import pyarrow as pa

class ArrowSQLExtractor(SQLExtractor):
    """SQL Extractor —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Apache Arrow"""
    
    async def _format_output(self, data):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Arrow"""
        if self.config.output_format == "arrow":
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º pandas DataFrame –≤ Arrow Table
            return pa.Table.from_pandas(data)
        else:
            return await super()._format_output(data)
```

## üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### 1. ETL Pipeline —Å Temporal

```python
from temporalio import workflow, activity
from extractor_sql import SQLExtractor, SQLExtractorConfig, QueryConfig

@activity.defn
async def extract_user_data() -> dict:
    config = SQLExtractorConfig(
        connection_string=os.getenv("SOURCE_DB_URL"),
        query_config=QueryConfig(
            query="""
            SELECT user_id, name, email, last_login_at
            FROM users 
            WHERE updated_at > :last_sync
            """,
            parameters={"last_sync": datetime.now() - timedelta(days=1)}
        )
    )
    
    extractor = SQLExtractor(config)
    await extractor.initialize()
    
    context = ExecutionContext(
        pipeline_id="user_sync",
        stage_name="extract_users"
    )
    
    result = await extractor.execute(context)
    await extractor.cleanup()
    
    return {
        "data": result.data.to_dict("records"),
        "metadata": result.metadata.to_dict()
    }

@workflow.defn
class UserSyncWorkflow:
    @workflow.run
    async def run(self) -> str:
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ
        user_data = await workflow.execute_activity(
            extract_user_data,
            start_to_close_timeout=timedelta(minutes=10)
        )
        
        # –î–∞–ª—å–Ω–µ–π—à–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞...
        return f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(user_data['data'])} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
```

### 2. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

```python
import pandas as pd
from extractor_sql import SQLExtractor, SQLExtractorConfig, QueryConfig

class DataQualityChecker:
    def __init__(self, config: SQLExtractorConfig):
        self.extractor = SQLExtractor(config)
    
    async def check_data_quality(self) -> dict:
        await self.extractor.initialize()
        
        checks = {}
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NULL –∑–Ω–∞—á–µ–Ω–∏—è
        null_check_config = SQLExtractorConfig(
            connection_string=self.extractor.config.connection_string,
            query_config=QueryConfig(
                query="""
                SELECT 
                    column_name,
                    COUNT(*) as total_rows,
                    SUM(CASE WHEN column_value IS NULL THEN 1 ELSE 0 END) as null_count
                FROM information_schema.columns
                WHERE table_name = :table_name
                """,
                parameters={"table_name": "users"}
            )
        )
        
        context = ExecutionContext(pipeline_id="quality_check", stage_name="null_check")
        result = await self.extractor.execute(context)
        
        if result.success:
            checks["null_analysis"] = result.data
        
        await self.extractor.cleanup()
        return checks
```

### 3. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã

```python
from jinja2 import Template

class DynamicQueryExtractor:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
    
    async def extract_with_template(self, template_str: str, **kwargs):
        # –†–µ–Ω–¥–µ—Ä–∏–º SQL —à–∞–±–ª–æ–Ω
        template = Template(template_str)
        rendered_query = template.render(**kwargs)
        
        config = SQLExtractorConfig(
            connection_string=self.connection_string,
            query_config=QueryConfig(query=rendered_query)
        )
        
        extractor = SQLExtractor(config)
        await extractor.initialize()
        
        context = ExecutionContext(
            pipeline_id="dynamic_query",
            stage_name="template_extraction"
        )
        
        result = await extractor.execute(context)
        await extractor.cleanup()
        
        return result

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
extractor = DynamicQueryExtractor("postgresql://...")

sql_template = """
SELECT {{ columns | join(', ') }}
FROM {{ table_name }}
WHERE {{ date_column }} BETWEEN '{{ start_date }}' AND '{{ end_date }}'
{% if filters %}
  AND {{ filters | join(' AND ') }}
{% endif %}
ORDER BY {{ order_by }}
"""

result = await extractor.extract_with_template(
    sql_template,
    columns=["id", "name", "email"],
    table_name="users",
    date_column="created_at",
    start_date="2024-01-01",
    end_date="2024-01-31",
    filters=["is_active = true", "department = 'Engineering'"],
    order_by="created_at DESC"
)
```

## ü§ù –£—á–∞—Å—Ç–∏–µ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

–ú—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ–º –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –ø—Ä–æ–µ–∫—Ç–∞! 

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/company/pipeline-framework.git
cd pipeline-framework

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
uv sync --group dev

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ pre-commit hooks
pre-commit install

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
pytest
```

### –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Å—Ç–∏–ª—é –∫–æ–¥–∞

- –ò—Å–ø–æ–ª—å–∑—É–µ–º `ruff` –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ª–∏–Ω—Ç–∏–Ω–≥–∞
- –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å > 85%
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ type hints
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ Google docstrings

### –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π

1. –°–æ–∑–¥–∞–π—Ç–µ feature branch: `git checkout -b feature/amazing-feature`
2. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã
3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç: `pytest`
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–∏–Ω—Ç–∏–Ω–≥: `ruff check .`
5. –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: `git commit -m 'Add amazing feature'`
6. –û—Ç–ø—Ä–∞–≤—å—Ç–µ branch: `git push origin feature/amazing-feature`
7. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ MIT License - —Å–º. —Ñ–∞–π–ª [LICENSE](LICENSE) –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

## üôã‚Äç‚ôÇÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∫–∞

- üìß Email: [support@company.com](mailto:support@company.com)
- üí¨ Slack: [#pipeline-framework](https://company.slack.com/channels/pipeline-framework)
- üêõ Issues: [GitHub Issues](https://github.com/company/pipeline-framework/issues)
- üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: [https://docs.pipeline-framework.com](https://docs.pipeline-framework.com)

## üó∫Ô∏è Roadmap

- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ë–î (ClickHouse, DuckDB)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å dbt –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ schema discovery
- [ ] GraphQL endpoint –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Apache Iceberg
- [ ] Real-time streaming —á–µ—Ä–µ–∑ Kafka
- [ ] Web UI –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

---

## üìã Changelog

### v0.1.0 (2024-01-20)

#### Added
- –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å SQL Extractor
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ PostgreSQL, MySQL, SQLite
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å SQLAlchemy
- Connection pooling –∏ retry –º–µ—Ö–∞–Ω–∏–∑–º—ã
- CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- Comprehensive test suite
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã

#### Security
- –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–æ–ª–µ–π –≤ –ª–æ–≥–∞—Ö
- –í–∞–ª–∏–¥–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–æ–≤
- Secure connection strings handling

---

*–°–æ–∑–¥–∞–Ω–æ —Å ‚ù§Ô∏è –∫–æ–º–∞–Ω–¥–æ–π Data Engineering*