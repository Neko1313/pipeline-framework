[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "pipeline-extractors"
description = "Компоненты для извлечения данных в pipeline фреймворке"
readme = "README.md"
license = { text = "Apache-2.0" }
authors = [
    { name = "Pipeline Framework Team", email = "team@example.com" },
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: System :: Distributed Computing",
    "Topic :: Database",
]
keywords = ["pipeline", "etl", "data-extraction", "extractors"]
requires-python = ">=3.11"
dependencies = [
    "pipeline-core",
    "pandas>=2.0.0",
    "polars>=0.20.0",
    "httpx>=0.25.0",
    "aiofiles>=23.0.0",
    "aiocsv>=1.3.0",
]
dynamic = ["version"]

[project.optional-dependencies]
# Database extractors
database = [
    "asyncpg>=0.28.0",          # PostgreSQL
    "aiomysql>=0.2.0",          # MySQL
    "motor>=3.3.0",             # MongoDB
    "sqlalchemy[asyncio]>=2.0.0", # SQL ORM
]

# Cloud storage extractors
cloud = [
    "boto3>=1.34.0",            # AWS S3
    "google-cloud-storage>=2.10.0", # Google Cloud Storage
    "azure-storage-blob>=12.19.0",  # Azure Blob Storage
]

# API extractors
api = [
    "httpx[http2]>=0.25.0",     # HTTP/2 support
    "aiohttp>=3.9.0",           # Alternative HTTP client
    "oauth2lib>=1.1.0",         # OAuth support
]

# File format support
formats = [
    "openpyxl>=3.1.0",          # Excel files
    "xlrd>=2.0.0",              # Old Excel format
    "pyarrow>=14.0.0",          # Parquet files
    "lxml>=4.9.0",              # XML parsing
    "beautifulsoup4>=4.12.0",   # HTML parsing
]

dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.6.0",
    "pyright>=1.1.380",
    "pre-commit>=3.4.0",
]

all = [
    "pipeline-extractors[database,cloud,api,formats]"
]

[project.urls]
Homepage = "https://github.com/your-org/pipeline-framework"
Documentation = "https://pipeline-framework.readthedocs.io"
Repository = "https://github.com/your-org/pipeline-framework"
Issues = "https://github.com/your-org/pipeline-framework/issues"

[tool.hatch.version]
path = "src/pipeline_extractors/__init__.py"

[tool.hatch.build.targets.wheel]
packages = ["src/pipeline_extractors"]

# Entry points для автоматической регистрации компонентов
[project.entry-points."pipeline.components"]
csv-extractor = "pipeline_extractors.file.csv_extractor:CSVExtractor"
json-extractor = "pipeline_extractors.file.json_extractor:JSONExtractor"
excel-extractor = "pipeline_extractors.file.excel_extractor:ExcelExtractor"
sql-extractor = "pipeline_extractors.database.sql_extractor:SQLExtractor"
postgresql-extractor = "pipeline_extractors.database.postgresql_extractor:PostgreSQLExtractor"
http-extractor = "pipeline_extractors.api.http_extractor:HTTPExtractor"
rest-api-extractor = "pipeline_extractors.api.rest_api_extractor:RestAPIExtractor"

[tool.ruff]
target-version = "py311"
line-length = 100

[tool.ruff.lint]
select = [
    "E", "W", "F", "I", "B", "C4", "UP", "SIM", "TCH", "PTH", "RUF",
]
ignore = [
    "E501", "B008", "C901", "SIM108",
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]
"tests/**/*" = ["B011", "S101"]

[tool.pyright]
include = ["src", "tests"]
exclude = ["**/__pycache__"]
pythonVersion = "3.13"
typeCheckingMode = "strict"